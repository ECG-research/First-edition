{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\OneDrive\\Desktop\\Python\\Python310\\python_work\\Model\\First-edition\\Model.py:20: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import Preprocessing as P\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "########### import model ############\n",
    "# import xResNet as m\n",
    "# import Inception1d as m\n",
    "import Modified_model1 as m\n",
    "#hyperparameters\n",
    "path = \"\"\n",
    "sampling_rate = 100\n",
    "num_eporch = 10\n",
    "thresh_hold = 0.5\n",
    "\n",
    "#network\n",
    "# net = m.inception1d().float()\n",
    "# net = m.xresnet1d50_deeper().float() #could be other types of xresnet, see xResNet.py for more info\n",
    "net = m.modified_version().float()\n",
    "#initialize criterion, optimizer\n",
    "criterion = nn.functional.binary_cross_entropy_with_logits\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "data = P.Preprocessing(path,sampling_rate,experiment=\"diagnostic_superclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "data_loader"
    ]
   },
   "outputs": [],
   "source": [
    "X = data.get_data_x()\n",
    "# x_train = np.concatenate((X[0][0],X[0][1],X[0][2]),axis = 1)\n",
    "x_train = [torch.from_numpy(X[0][i])for i in range(3)]\n",
    "# x_val = np.concatenate((X[1][0],X[1][1],X[1][2]),axis = 1)\n",
    "x_val = [torch.from_numpy(X[1][i])for i in range(3)]\n",
    "# x_test = np.concatenate((X[2][0],X[2][1],X[2][2]),axis = 1)\n",
    "x_test = [torch.from_numpy(X[2][i])for i in range(3)]\n",
    "\n",
    "Y = data.get_data_y()\n",
    "y_train = torch.from_numpy(Y[0])\n",
    "y_val = torch.from_numpy(Y[1])\n",
    "y_test = torch.from_numpy(Y[2])\n",
    "\n",
    "Sle = data.get_data_metadata()\n",
    "sle_train = torch.from_numpy(Sle[0])\n",
    "sle_val = torch.from_numpy(Sle[1])\n",
    "sle_test = torch.from_numpy(Sle[2])\n",
    "#dataloader\n",
    "train_data = DataLoader(TensorDataset(x_train[0],x_train[1],x_train[2],sle_train,y_train), batch_size=200, shuffle=True)\n",
    "val_data = DataLoader(TensorDataset(x_val[0],x_val[1],x_val[2],sle_val,y_val), batch_size = 200, shuffle=False)\n",
    "test_data = DataLoader(TensorDataset(x_test[0],x_test[1],x_test[2],sle_test,y_test), batch_size = 200, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "train"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:/n-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/88 [00:05<?, ?it/s]\n",
      "  0%|          | 0/10 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'pop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     13\u001b[0m \u001b[39m# inputs = [input1.float(),input2.float(),input3.float()]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[39m# forward + backward + optimize\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m outputs \u001b[39m=\u001b[39m net(input1\u001b[39m.\u001b[39;49mfloat(),input2\u001b[39m.\u001b[39;49mfloat(),input3\u001b[39m.\u001b[39;49mfloat(),metadata\u001b[39m.\u001b[39;49mfloat())\n\u001b[0;32m     17\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels\u001b[39m.\u001b[39mfloat())\n\u001b[0;32m     18\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Admin\\OneDrive\\Desktop\\Python\\Python310\\python_work\\Model\\First-edition\\Modified_model1.py:95\u001b[0m, in \u001b[0;36mModified_version.forward\u001b[1;34m(self, x0, x1, x2, metadata)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m#multiple head attention\u001b[39;00m\n\u001b[0;32m     94\u001b[0m metadata \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39m32\u001b[39m,\u001b[39m384\u001b[39m)(metadata)\n\u001b[1;32m---> 95\u001b[0m feature1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mMHAttention(feature,metadata,metadata)\n\u001b[0;32m     96\u001b[0m feature2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMHAttention(metadata,feature,feature)\n\u001b[0;32m     97\u001b[0m enhanced_feature \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((feature1,feature2),dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\OneDrive\\Desktop\\Python\\Python310\\python_work\\Model\\First-edition\\Modified_model1.py:102\u001b[0m, in \u001b[0;36mModified_version.MHAttention\u001b[1;34m(self, query, key, value, num_head, dropout, batch_first)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mMHAttention\u001b[39m(\u001b[39mself\u001b[39m,query,key,value,num_head\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,dropout \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m,batch_first \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    101\u001b[0m     x \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMultiheadAttention(query\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],num_heads\u001b[39m=\u001b[39mnum_head,dropout\u001b[39m=\u001b[39mdropout,batch_first\u001b[39m=\u001b[39mbatch_first)(query,key,value,need_weights \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 102\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mpop()\n\u001b[0;32m    103\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39madd(x,query)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'pop'"
     ]
    }
   ],
   "source": [
    "#train\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "for epoch in tqdm(range(num_eporch)):\n",
    "    net.train()\n",
    "    print(\"Epoch {}:/n-----------------------------------------------------------\".format(epoch +1)) \n",
    "    \n",
    "    for input1, input2, input3, metadata, labels in tqdm(train_data):\n",
    "        running_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        # inputs = [input1.float(),input2.float(),input3.float()]\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(input1.float(),input2.float(),input3.float(),metadata.float())\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # calculate output accuracy\n",
    "        pred = outputs.detach().numpy() > thresh_hold\n",
    "        acc = (pred == labels.detach().numpy()).sum()/(input1.shape[0]*5)\n",
    "        \n",
    "        # store loss\n",
    "        running_loss += loss.item()\n",
    "        train_loss.append(loss.item())\n",
    "        train_acc.append(acc)\n",
    "        print(\"epoch{}: loss per batch:{:.4f}\".format(epoch+1, running_loss))\n",
    "        print(\"Accuracy of epoch{} per batch:{}\".format(epoch+1, acc*100))\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        running_loss = 0.0\n",
    "        correct_val = 0\n",
    "        for input1, input2, input3, metadata, labels in tqdm(train_data):\n",
    "            # inputs = [input1.float(),input2.float(),input3.float()]\n",
    "            # forward + backward + optimize\n",
    "            ooutputs = net(input1.float(),input2.float(),input3.float(),metadata.float())\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            # calculate output acc\n",
    "            pred = outputs.detach().numpy() > thresh_hold\n",
    "            acc = (pred == labels.detach().numpy()).sum()\n",
    "            correct_val += acc\n",
    "            #store loss\n",
    "            running_loss += loss.item()\n",
    "            val_loss.append(loss.item())\n",
    "            val_acc.append(acc/(input1.shape[0]*5))\n",
    "        print(\"========================================================\")\n",
    "        print(\"Validation loss of epoch{}:{:.4f}\".format(epoch+1,running_loss))\n",
    "        print(\"Accuracy of epoch{}:{}\".format(epoch+1, correct_val*100/(y_val.shape[0]*5)))\n",
    "\n",
    "print(\"\\nfinished training =================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(2)\n",
    "# training plot\n",
    "axis[0].plot(val_acc,label=\"val\")\n",
    "axis[0].plot(train_acc,label=\"train\")\n",
    "axis[0].set_title(\"accuracy\")\n",
    "# validation plot\n",
    "axis[1].plot(val_loss,label=\"val\")\n",
    "axis[1].plot(train_loss,label=\"train\")\n",
    "axis[1].set_title(\"loss\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = []\n",
    "test_acc = []\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    batch_test = []\n",
    "    for inputs, labels in tqdm(test_data):\n",
    "        outputs = net(inputs.float())\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        pred = outputs.detach().numpy() > thresh_hold\n",
    "        acc = (pred == labels.detach().numpy()).sum()/(inputs.shape[0]*5)\n",
    "        batch_test.append(acc)\n",
    "        running_loss += loss.item()\n",
    "        test_loss.append(loss.item())\n",
    "        test_acc.append(acc)\n",
    "print(\"========================================================\")\n",
    "print(\"Test loss:{:.4f}\".format(sum(test_loss)/len(test_loss)))    \n",
    "print(\"Test accuracy:{:}\".format(sum(batch_test)/len(batch_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58dbfdb34cf82127b32c5737e6183911655ff227e5c11e8f5e4b25048ae98ef2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
